{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6df0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.session import Session,col\n",
    "import snowflake.snowpark.functions\n",
    "from snowflake.ml.modeling.metrics import confusion_matrix, accuracy_score, f1_score, recall_score,precision_score\n",
    "from snowflake.ml.modeling.preprocessing import LabelEncoder, StandardScaler\n",
    "from snowflake.ml.modeling.impute import SimpleImputer\n",
    "from snowflake.ml.modeling.ensemble import GradientBoostingClassifier\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "import snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ab9c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import os\n",
    "# connection_parameters = { \"account\": \"ug94937\", \"user\": \"AAVESH\", \"password\": \"Panchi@202219\", \"role\": \"AAVESH\", \"warehouse\": \"FOSFOR_INSIGHT_WH\",  \"database\": \"FDC_DEV_AAVESH\", \"schema\": \"FDC_DEV_AAVESH\",\"region\":\"us-east4.gcp\"}\n",
    "# new_session = Session.builder.configs(connection_parameters).create()\n",
    "# exp_details = {\"name\": \"SnowparK_ml\", \"algo_details\": {\"snowflake.ml.modeling.ensemble.GradientBoostingClassifier\": \"null\"}, \"id\": \"330\", \"dataset\": \"HR_BINARY\", \"target_column\": \"SALARY\"}\n",
    "# os.environ['EXPERIMENT_DETAILS'] = json.dumps(exp_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f12f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "print(f\"Starting Experiment Execution with the following params:\\n{os.getenv('EXPERIMENT_DETAILS')}\\n\")\n",
    "exp_details=json.loads(os.getenv(\"EXPERIMENT_DETAILS\"))\n",
    "exp_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618936c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conn_details_from_ds_name(dataset_name, project_id):\n",
    "    \"\"\"\n",
    "    To get connection details by using dataset_name and project_id from connection manager API.\n",
    "    :param dataset_name:\n",
    "    :param project_id:\n",
    "    :return: connection_details\n",
    "    \"\"\"\n",
    "    connection_manager = os.getenv(\"CONNECTION_MANAGER_BASE_URL\", \"http://fdc-project-manager:80/project-manager\")\n",
    "    #https://dev.fdc.leni.ai/project-manager/connections/api/ConnectionManager/v1/allConnections?projectId=6a3f39a4-fad3-4f32-b31c-a706dc2f4a35\n",
    "    url = f\"{connection_manager}/connections/api/ConnectionManager/v1/allConnections?projectId={project_id}\"\n",
    "    return requests.get(url, verify=False).json()\n",
    "\n",
    "connection_details = get_conn_details_from_ds_name(\"HR_DATA\", os.getenv(\"PROJECT_ID\"))\n",
    "connection_parameters = {\n",
    "        \"user\": connection_details[0][\"connectionDetails\"][\"dbUserName\"],\n",
    "        \"password\": connection_details[0][\"connectionDetails\"][\"dbPassword\"],\n",
    "        \"account\": connection_details[0][\"connectionDetails\"][\"accountName\"],\n",
    "        \"database\": connection_details[0][\"connectionDetails\"][\"defaultDb\"],\n",
    "        \"role\": connection_details[0][\"connectionDetails\"][\"role\"],\n",
    "        \"cloudPlatform\": connection_details[0][\"connectionDetails\"][\"cloudPlatform\"],\n",
    "        \"schema\": connection_details[0][\"connectionDetails\"][\"defaultSchema\"],\n",
    "        \"wareHouse\": connection_details[0][\"connectionDetails\"][\"wareHouse\"],\n",
    "        \"region\": connection_details[0][\"connectionDetails\"][\"region\"] + \".\" + connection_details[0][\"connectionDetails\"][\"cloudPlatform\"]\n",
    "}\n",
    "print(connection_parameters)\n",
    "\n",
    "new_session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3536e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_session.query_tag = exp_details.get(\"description\", \"sample_description\")\n",
    "dataset_name = exp_details.get(\"dataset\")\n",
    "df = new_session.table(dataset_name)\n",
    "input_data_frame, test_df = df.randomSplit([0.75, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e752dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_label_encoding(input_data_frame):\n",
    "    for i in input_data_frame.dtypes:\n",
    "        if i[1].find('string') >= 0:\n",
    "            label_encoder = LabelEncoder(input_cols=i[0],output_cols=i[0],drop_input_cols=True)\n",
    "            input_data_frame = label_encoder.fit(input_data_frame).transform(input_data_frame)\n",
    "    return input_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2346d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_column = []     \n",
    "input_data_frame = apply_label_encoding(input_data_frame)\n",
    "feature_cols = input_data_frame.columns\n",
    "target_col = exp_details.get(\"target_column\")\n",
    "feature_cols.remove(target_col)\n",
    "input_data_frame.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de504316-b5eb-4650-a871-d62b3d8bde88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib \n",
    "algo_name = exp_details.get(\"algo_details\")\n",
    "algo_name = list(algo_name.keys())[0]\n",
    "module_name = algo_name[0:algo_name.rindex(\".\")]\n",
    "class_name = algo_name[algo_name.rindex(\".\")+1:len(algo_name)]\n",
    "cls = getattr(importlib.import_module(module_name), class_name)\n",
    "pipeline = cls(input_cols=feature_cols, label_cols=target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3fd02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(input_data_frame)\n",
    "test_df = apply_label_encoding(test_df)\n",
    "scored_df = pipeline.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d54ece3-eb1d-4be1-aac2-ff9310b3446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_or(fn):\n",
    "    try:\n",
    "        out = fn()\n",
    "        return out\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "OUTPUT_COLS = 'OUTPUT_' + target_col\n",
    "metrics_json = {}\n",
    "try:\n",
    "    accurary = try_or(lambda: accuracy_score(df=scored_df, y_true_col_names=OUTPUT_COLS, y_pred_col_names=target_col))\n",
    "    precision_score11 = try_or(lambda: precision_score(df=scored_df, y_true_col_names=OUTPUT_COLS, y_pred_col_names=target_col))\n",
    "    recall =  try_or(lambda: recall_score(df=scored_df, y_true_col_names=OUTPUT_COLS, y_pred_col_names=target_col))\n",
    "    f1= try_or(lambda: f1_score(df=scored_df, y_true_col_names=OUTPUT_COLS, y_pred_col_names=target_col))\n",
    "    metrics_json = {'accuracy_score': accurary, \"f1_score\":f1, \"recall_score\": recall, \"score\": accurary, \"precision_score\": precision_score11}\n",
    "except Exception as me:\n",
    "    from snowflake.ml.modeling.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    mean_squared_error = try_or(\n",
    "        lambda: mean_squared_error(df=scored_df, y_true_col_names=OUTPUT_COLS, y_pred_col_names=target_col))\n",
    "    mean_absolute_error = try_or(\n",
    "        lambda: mean_absolute_error(df=scored_df, y_true_col_names=OUTPUT_COLS, y_pred_col_names=target_col))\n",
    "    r2_score1 = try_or(lambda: r2_score(df=scored_df, y_true_col_name=OUTPUT_COLS, y_pred_col_name=target_col))\n",
    "    import numpy as np\n",
    "    metrics_json = {\"rmse\": np.sqrt(mean_squared_error), \"mae\": mean_absolute_error, \"r2\": r2_score1}\n",
    "\n",
    "metrics_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4471c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.registry import Registry\n",
    "\n",
    "reg = Registry(session=new_session, database_name=connection_parameters[\"database\"], schema_name=connection_parameters[\"schema\"])\n",
    "mv = reg.log_model(pipeline,\n",
    "                   model_name=exp_details.get(\"name\", \"sample_experiment\"),\n",
    "                   version_name=\"v2\",\n",
    "                   comment=exp_details.get(\"description\", \"sample_description\"),\n",
    "                   conda_dependencies=['scikit-learn==1.3.0'],\n",
    "                   metrics=metrics_json,\n",
    "                   sample_input_data=input_data_frame.columns,\n",
    "                   python_version=\"3.9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8d0a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_and_dump_func(file_path):\n",
    "    \"\"\"\n",
    "    :param\n",
    "    file_path\n",
    "    \"\"\"\n",
    "\n",
    "    def score_func(model, request):\n",
    "        \"\"\"\n",
    "        :param\n",
    "        model\n",
    "        request\n",
    "        :returns\n",
    "        score_output\n",
    "        \"\"\"\n",
    "        # Enter your custom score function here\n",
    "\n",
    "        score_output = \"Success\"\n",
    "        return score_output\n",
    "\n",
    "    with open(file_path, \"wb\") as out:\n",
    "        cloudpickle.dump(score_func, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da8094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "import cloudpickle\n",
    "import json\n",
    "\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URL\", \"http://mlflow-server\"))\n",
    "mlflow.set_experiment(exp_details.get(\"name\", \"sample_experiment\"))\n",
    "tags = {'mlflow.note.content': exp_details.get(\"description\", \"sample_description\")}\n",
    "params = pipeline.to_sklearn().get_params()\n",
    "for i in metrics_json:\n",
    "    mlflow.log_metric(i, metrics_json[i])\n",
    "\n",
    "algorithm_name = str(pipeline.to_sklearn()).replace(\"()\",\"\")\n",
    "for k in pipeline.to_sklearn().get_params():\n",
    "    mlflow.log_param(algorithm_name + \"_\" + str(k),pipeline.to_sklearn().get_params()[k])\n",
    "\n",
    "dataset = mlflow.data.from_pandas(input_data_frame.to_pandas(), source=\"input\")\n",
    "mlflow.log_input(dataset, context=\"input\")\n",
    "# Set custom tags\n",
    "mlflow.set_tags({\n",
    "    \"template_id\": os.getenv(\"template_id\", \"sample_template_id\"),\n",
    "    \"notebook_name\": os.getenv(\"notebook_name\", \"sample_notebook_name\"),\n",
    "    \"algorithm\": algorithm_name,\n",
    "    \"algo_details\": exp_details.get(\"algo_details\")\n",
    "})\n",
    "signature = infer_signature(input_data_frame.to_pandas(), scored_df.to_pandas()[target_col])\n",
    "# Storing score function for the model\n",
    "score_and_dump_func(\"/tmp/scoring_func\")\n",
    "mlflow.log_artifact(\"/tmp/scoring_func\")\n",
    "#Register the model\n",
    "mlflow.sklearn.log_model(\n",
    "    pipeline.to_sklearn(), \"model\",\n",
    "    registered_model_name=exp_details.get(\"name\", \"sample_experiment\"), signature=signature\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a6e076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61697def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
